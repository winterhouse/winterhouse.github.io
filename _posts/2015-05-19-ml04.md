---
layout: post
title: Machine Learning04:classification & representation
description: 
category: blog
---

对于linear regression来说，我们可以选用不同的函数形式来拟合不同分布表现的数据，但我们仍然会得到一条linear function形态的hypothesis，因为我们选用不同的函数形式，实际上是对feature的重新利用而不是真正选用了新的函数形式。

如果我们要对离散的数据进行拟合，即classification，那么就需要用到logistic regression，而logistic regression是真正的改变了函数形式。

在linear regression中，hypothesis的形式为h(x) = θ*x

######sigmoid function(logistic function)

![13](http://picturereq.herokuapp.com/images/coursera/ml_13.png)

[wiki](http://en.wikipedia.org/wiki/Logistic_function)

![08](http://picturereq.herokuapp.com/images/coursera/ml_08.png)

我们很早就接触过这个函数，在生物上，当一个物种迁入到一个新生态系统中后，其数量会发生变化。假设该物种的起始数量小于环境的最大容纳量，则数量会增长。该物种在此生态系统中有天敌、食物、空间等资源也不足（非理想环境），最后会达到一个上线，logistics function就很完美的表达了这个增长趋势。

hypothesis 的形式为：hθ(x)  = P(θ*x)

#####interpretation of hypothesis output

假设只有两个class 即0，1，非0即1.

h(x) = 0.7 表示h预测输入x，有70%的概率输出是1 ，h(x) = P(y = 1 | x;θ)

P(y = 1 | x;θ) + P(y = 0 | x;θ) = 1

#####decision boundary

![09](http://picturereq.herokuapp.com/images/coursera/ml_08.png)

当h(θx)>0.5时，我们预测y =1 , 观察logistics function的图像可以发现，也就是 θ*x>0时，我们预测 y = 1，θ也就是一个划分x的界限，被称为decision boundary。

在decision boundary一侧的预测为0，另一侧预测为1。

decision boundary由θ决定，我们需要做的就是用训练集中的数据不断调整decision boundary，直到让它达到最合适的值，也就是不断调整θ。

例如，两类用例分布如下图，在图中任意画一条曲线，直线，图形都可以称为是一个decision boundary，但是最合适的decision boundary应该是如第二幅图所示的一条直线。

-24.932999 +x1*0.204408 +x2*0.199618 = 0

那么最适合输入的θ就应该是 [ -24.932999, 0.204408 ,0.199618 ]

![09](http://picturereq.herokuapp.com/images/coursera/ml_12.png)
![10](http://picturereq.herokuapp.com/images/coursera/ml_11.png)